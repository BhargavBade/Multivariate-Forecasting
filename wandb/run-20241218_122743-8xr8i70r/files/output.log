Epoch [1/200], Loss: 0.0743
Epoch [2/200], Loss: 0.0664
Epoch [3/200], Loss: 0.0659
Epoch [4/200], Loss: 0.0644
Epoch [5/200], Loss: 0.0633
-- Evaluation after Epoch [5/200], Test Loss: 0.1052
New best test loss: 0.1052. Saving model.
Epoch [6/200], Loss: 0.0626
Epoch [7/200], Loss: 0.0621
Epoch [8/200], Loss: 0.0615
Epoch [9/200], Loss: 0.0610
Epoch [10/200], Loss: 0.0597
-- Evaluation after Epoch [10/200], Test Loss: 0.1046
New best test loss: 0.1046. Saving model.
Epoch [11/200], Loss: 0.0594
Epoch [12/200], Loss: 0.0589
Epoch [13/200], Loss: 0.0587
Epoch [14/200], Loss: 0.0583
Epoch [15/200], Loss: 0.0580
-- Evaluation after Epoch [15/200], Test Loss: 0.0923
New best test loss: 0.0923. Saving model.
Epoch [16/200], Loss: 0.0576
Epoch [17/200], Loss: 0.0573
Epoch [18/200], Loss: 0.0565
Epoch [19/200], Loss: 0.0562
Epoch [20/200], Loss: 0.0564
-- Evaluation after Epoch [20/200], Test Loss: 0.0919
New best test loss: 0.0919. Saving model.
Epoch [21/200], Loss: 0.0554
Epoch [22/200], Loss: 0.0554
Epoch [23/200], Loss: 0.0549
Epoch [24/200], Loss: 0.0547
Epoch [25/200], Loss: 0.0541
-- Evaluation after Epoch [25/200], Test Loss: 0.0788
New best test loss: 0.0788. Saving model.
Epoch [26/200], Loss: 0.0546
Epoch [27/200], Loss: 0.0537
Epoch [28/200], Loss: 0.0533
Epoch [29/200], Loss: 0.0538
Epoch [30/200], Loss: 0.0533
-- Evaluation after Epoch [30/200], Test Loss: 0.0906
Epoch [31/200], Loss: 0.0531
Epoch [32/200], Loss: 0.0527
Epoch [33/200], Loss: 0.0519
Epoch [34/200], Loss: 0.0525
Epoch [35/200], Loss: 0.0528
-- Evaluation after Epoch [35/200], Test Loss: 0.1010
Epoch [36/200], Loss: 0.0519
Epoch [37/200], Loss: 0.0510
Epoch [38/200], Loss: 0.0512
Epoch [39/200], Loss: 0.0501
Epoch [40/200], Loss: 0.0495
-- Evaluation after Epoch [40/200], Test Loss: 0.0743
New best test loss: 0.0743. Saving model.
Epoch [41/200], Loss: 0.0495
Epoch [42/200], Loss: 0.0500
Epoch [43/200], Loss: 0.0495
Epoch [44/200], Loss: 0.0491
Epoch [45/200], Loss: 0.0488
-- Evaluation after Epoch [45/200], Test Loss: 0.0856
Epoch [46/200], Loss: 0.0487
Epoch [47/200], Loss: 0.0490
Epoch [48/200], Loss: 0.0467
Epoch [49/200], Loss: 0.0471
Epoch [50/200], Loss: 0.0483
-- Evaluation after Epoch [50/200], Test Loss: 0.0735
New best test loss: 0.0735. Saving model.
Epoch [51/200], Loss: 0.0470
Epoch [52/200], Loss: 0.0463
Epoch [53/200], Loss: 0.0477
Epoch [54/200], Loss: 0.0466
Epoch [55/200], Loss: 0.0453
-- Evaluation after Epoch [55/200], Test Loss: 0.0872
Epoch [56/200], Loss: 0.0451
Epoch [57/200], Loss: 0.0446
Epoch [58/200], Loss: 0.0454
Epoch [59/200], Loss: 0.0439
Epoch [60/200], Loss: 0.0439
-- Evaluation after Epoch [60/200], Test Loss: 0.0836
Epoch [61/200], Loss: 0.0444
Epoch [62/200], Loss: 0.0446
Epoch [63/200], Loss: 0.0430
Epoch [64/200], Loss: 0.0434
Epoch [65/200], Loss: 0.0445
-- Evaluation after Epoch [65/200], Test Loss: 0.0828
Epoch [66/200], Loss: 0.0423
Epoch [67/200], Loss: 0.0440
Epoch [68/200], Loss: 0.0421
Epoch [69/200], Loss: 0.0425
Epoch [70/200], Loss: 0.0422
-- Evaluation after Epoch [70/200], Test Loss: 0.0786
Epoch [71/200], Loss: 0.0417
Epoch [72/200], Loss: 0.0419
Epoch [73/200], Loss: 0.0404
Epoch [74/200], Loss: 0.0399
Epoch [75/200], Loss: 0.0394
-- Evaluation after Epoch [75/200], Test Loss: 0.0851
Epoch [76/200], Loss: 0.0411
Epoch [77/200], Loss: 0.0409
Epoch [78/200], Loss: 0.0402
Epoch [79/200], Loss: 0.0394
Epoch [80/200], Loss: 0.0386
-- Evaluation after Epoch [80/200], Test Loss: 0.0858
Epoch [81/200], Loss: 0.0385
Epoch [82/200], Loss: 0.0395
Epoch [83/200], Loss: 0.0387
Epoch [84/200], Loss: 0.0376
Epoch [85/200], Loss: 0.0377
-- Evaluation after Epoch [85/200], Test Loss: 0.0781
Epoch [86/200], Loss: 0.0392
Epoch [87/200], Loss: 0.0378
Epoch [88/200], Loss: 0.0369
Epoch [89/200], Loss: 0.0386
Epoch [90/200], Loss: 0.0366
-- Evaluation after Epoch [90/200], Test Loss: 0.0689
New best test loss: 0.0689. Saving model.
Epoch [91/200], Loss: 0.0361
Epoch [92/200], Loss: 0.0357
Epoch [93/200], Loss: 0.0359
Epoch [94/200], Loss: 0.0358
Epoch [95/200], Loss: 0.0365
-- Evaluation after Epoch [95/200], Test Loss: 0.0698
Epoch [96/200], Loss: 0.0367
Epoch [97/200], Loss: 0.0363
Epoch [98/200], Loss: 0.0354
Epoch [99/200], Loss: 0.0359
Epoch [100/200], Loss: 0.0356
-- Evaluation after Epoch [100/200], Test Loss: 0.0670
New best test loss: 0.0670. Saving model.
Epoch [101/200], Loss: 0.0348
Epoch [102/200], Loss: 0.0339
Epoch [103/200], Loss: 0.0341
Epoch [104/200], Loss: 0.0346
Epoch [105/200], Loss: 0.0354
-- Evaluation after Epoch [105/200], Test Loss: 0.0690
Epoch [106/200], Loss: 0.0335
Epoch [107/200], Loss: 0.0330
Epoch [108/200], Loss: 0.0331
Epoch [109/200], Loss: 0.0339
Epoch [110/200], Loss: 0.0336
-- Evaluation after Epoch [110/200], Test Loss: 0.0737
Epoch [111/200], Loss: 0.0329
Epoch [112/200], Loss: 0.0330
Epoch [113/200], Loss: 0.0323
Epoch [114/200], Loss: 0.0328
Epoch [115/200], Loss: 0.0325
-- Evaluation after Epoch [115/200], Test Loss: 0.0715
Epoch [116/200], Loss: 0.0327
Epoch [117/200], Loss: 0.0324
Epoch [118/200], Loss: 0.0316
Epoch [119/200], Loss: 0.0317
Epoch [120/200], Loss: 0.0314
-- Evaluation after Epoch [120/200], Test Loss: 0.0665
New best test loss: 0.0665. Saving model.
Epoch [121/200], Loss: 0.0326
Epoch [122/200], Loss: 0.0335
Epoch [123/200], Loss: 0.0341
Epoch [124/200], Loss: 0.0317
Epoch [125/200], Loss: 0.0324
-- Evaluation after Epoch [125/200], Test Loss: 0.0624
New best test loss: 0.0624. Saving model.
Epoch [126/200], Loss: 0.0315
Epoch [127/200], Loss: 0.0321
Epoch [128/200], Loss: 0.0324
Epoch [129/200], Loss: 0.0330
Epoch [130/200], Loss: 0.0350
-- Evaluation after Epoch [130/200], Test Loss: 0.0621
New best test loss: 0.0621. Saving model.
Epoch [131/200], Loss: 0.0358
Epoch [132/200], Loss: 0.0337
Epoch [133/200], Loss: 0.0325
Epoch [134/200], Loss: 0.0312
Epoch [135/200], Loss: 0.0317
-- Evaluation after Epoch [135/200], Test Loss: 0.0705
Epoch [136/200], Loss: 0.0346
Epoch [137/200], Loss: 0.0334
Epoch [138/200], Loss: 0.0353
Epoch [139/200], Loss: 0.0339
Epoch [140/200], Loss: 0.0335
-- Evaluation after Epoch [140/200], Test Loss: 0.0703
Epoch [141/200], Loss: 0.0352
Epoch [142/200], Loss: 0.0337
Epoch [143/200], Loss: 0.0335
Epoch [144/200], Loss: 0.0324
Epoch [145/200], Loss: 0.0314
-- Evaluation after Epoch [145/200], Test Loss: 0.0635
Epoch [146/200], Loss: 0.0324
Epoch [147/200], Loss: 0.0320
Epoch [148/200], Loss: 0.0328
Epoch [149/200], Loss: 0.0326
Epoch [150/200], Loss: 0.0327
-- Evaluation after Epoch [150/200], Test Loss: 0.0640
Epoch [151/200], Loss: 0.0326
Epoch [152/200], Loss: 0.0338
Epoch [153/200], Loss: 0.0335
Epoch [154/200], Loss: 0.0331
Epoch [155/200], Loss: 0.0325
-- Evaluation after Epoch [155/200], Test Loss: 0.0694
Epoch [156/200], Loss: 0.0318
Epoch [157/200], Loss: 0.0330
Epoch [158/200], Loss: 0.0327
Epoch [159/200], Loss: 0.0321
Epoch [160/200], Loss: 0.0336
-- Evaluation after Epoch [160/200], Test Loss: 0.0659
Epoch [161/200], Loss: 0.0358
Epoch [162/200], Loss: 0.0351
Epoch [163/200], Loss: 0.0335
Epoch [164/200], Loss: 0.0338
Epoch [165/200], Loss: 0.0325
-- Evaluation after Epoch [165/200], Test Loss: 0.0763
Epoch [166/200], Loss: 0.0310
Epoch [167/200], Loss: 0.0301
Epoch [168/200], Loss: 0.0300
Epoch [169/200], Loss: 0.0304
Epoch [170/200], Loss: 0.0303
-- Evaluation after Epoch [170/200], Test Loss: 0.0743
Epoch [171/200], Loss: 0.0300
Epoch [172/200], Loss: 0.0295
Epoch [173/200], Loss: 0.0299
Epoch [174/200], Loss: 0.0301
Epoch [175/200], Loss: 0.0305
-- Evaluation after Epoch [175/200], Test Loss: 0.0687
Epoch [176/200], Loss: 0.0298
Epoch [177/200], Loss: 0.0302
Epoch [178/200], Loss: 0.0305
Epoch [179/200], Loss: 0.0293
Epoch [180/200], Loss: 0.0313
-- Evaluation after Epoch [180/200], Test Loss: 0.0660
Epoch [181/200], Loss: 0.0297
Epoch [182/200], Loss: 0.0315
Epoch [183/200], Loss: 0.0307
Epoch [184/200], Loss: 0.0312
Epoch [185/200], Loss: 0.0317
-- Evaluation after Epoch [185/200], Test Loss: 0.0713
Epoch [186/200], Loss: 0.0335
Epoch [187/200], Loss: 0.0337
Epoch [188/200], Loss: 0.0332
Epoch [189/200], Loss: 0.0304
Epoch [190/200], Loss: 0.0291
-- Evaluation after Epoch [190/200], Test Loss: 0.0647
Epoch [191/200], Loss: 0.0275
Epoch [192/200], Loss: 0.0270
Epoch [193/200], Loss: 0.0287
Epoch [194/200], Loss: 0.0277
Epoch [195/200], Loss: 0.0278
-- Evaluation after Epoch [195/200], Test Loss: 0.0637
Epoch [196/200], Loss: 0.0285
Epoch [197/200], Loss: 0.0285
Epoch [198/200], Loss: 0.0296
Epoch [199/200], Loss: 0.0286
Epoch [200/200], Loss: 0.0279
-- Evaluation after Epoch [200/200], Test Loss: 0.0635
Loading the best model from checkpoint with test loss: 0.0621
Validation Loss (RMSE): 0.0411
Validation results saved to: ./Results\LSTMStudy_20241218_122640\Val\validation_results.txt
Avg Test Loss before reverse scaling(RMSE): 0.0621
Avg Test Loss after reverse scaling (RMSE): 49.9249
Test results saved to: ./Results\LSTMStudy_20241218_122640\Test\test_results.txt
[4;33mReloaded modules[24m: Network.lstm_network, study_folder, params, prepare_data02[0m
96
64
./Results\LSTMStudy_20241218_125215
./Results\LSTMStudy_20241218_125215\Train
Config file saved to: ./Results\LSTMStudy_20241218_125215\params.py
./01_PM2.5 Chinese Weather data\BeijingPM20100101_20151231.csv
PM index during scaling is: 8
Train data tensor shape: torch.Size([35387, 96, 11])
Train labels tensor shape: torch.Size([35387, 1])
Val data tensor shape: torch.Size([3705, 96, 11])
Val labels tensor shape: torch.Size([3705, 1])
Test data tensor shape: torch.Size([11310, 96, 11])
Test labels tensor shape: torch.Size([11310, 1])
Epoch [1/200], Loss: 0.0825
Epoch [2/200], Loss: 0.0675
Epoch [3/200], Loss: 0.0663
Epoch [4/200], Loss: 0.0658
Epoch [5/200], Loss: 0.0643
-- Evaluation after Epoch [5/200], Test Loss: 0.1071
New best test loss: 0.1071. Saving model.
Epoch [6/200], Loss: 0.0637
Epoch [7/200], Loss: 0.0624
Epoch [8/200], Loss: 0.0617
Epoch [9/200], Loss: 0.0606
Epoch [10/200], Loss: 0.0604
-- Evaluation after Epoch [10/200], Test Loss: 0.1063
New best test loss: 0.1063. Saving model.
Epoch [11/200], Loss: 0.0598
Epoch [12/200], Loss: 0.0595
Epoch [13/200], Loss: 0.0591
Epoch [14/200], Loss: 0.0585
Epoch [15/200], Loss: 0.0583
-- Evaluation after Epoch [15/200], Test Loss: 0.0920
New best test loss: 0.0920. Saving model.
Epoch [16/200], Loss: 0.0579
Epoch [17/200], Loss: 0.0574
Epoch [18/200], Loss: 0.0568
Epoch [19/200], Loss: 0.0570
Epoch [20/200], Loss: 0.0579
-- Evaluation after Epoch [20/200], Test Loss: 0.0822
New best test loss: 0.0822. Saving model.
Epoch [21/200], Loss: 0.0563
Epoch [22/200], Loss: 0.0549
Epoch [23/200], Loss: 0.0554
Epoch [24/200], Loss: 0.0546
Epoch [25/200], Loss: 0.0550
-- Evaluation after Epoch [25/200], Test Loss: 0.0846
Epoch [26/200], Loss: 0.0544
Epoch [27/200], Loss: 0.0536
Epoch [28/200], Loss: 0.0542
Epoch [29/200], Loss: 0.0547
Epoch [30/200], Loss: 0.0539
-- Evaluation after Epoch [30/200], Test Loss: 0.0827
Epoch [31/200], Loss: 0.0534
Epoch [32/200], Loss: 0.0525
Epoch [33/200], Loss: 0.0529
Epoch [34/200], Loss: 0.0529
Epoch [35/200], Loss: 0.0517
-- Evaluation after Epoch [35/200], Test Loss: 0.0847
Epoch [36/200], Loss: 0.0516
Epoch [37/200], Loss: 0.0525
Epoch [38/200], Loss: 0.0514
Epoch [39/200], Loss: 0.0527
Epoch [40/200], Loss: 0.0516
-- Evaluation after Epoch [40/200], Test Loss: 0.0907
Epoch [41/200], Loss: 0.0508
Epoch [42/200], Loss: 0.0507
Epoch [43/200], Loss: 0.0502
Epoch [44/200], Loss: 0.0495
Epoch [45/200], Loss: 0.0495
-- Evaluation after Epoch [45/200], Test Loss: 0.0792
New best test loss: 0.0792. Saving model.
Epoch [46/200], Loss: 0.0501
Epoch [47/200], Loss: 0.0501
Epoch [48/200], Loss: 0.0492
Epoch [49/200], Loss: 0.0492
Epoch [50/200], Loss: 0.0486
-- Evaluation after Epoch [50/200], Test Loss: 0.1001
Epoch [51/200], Loss: 0.0478
Epoch [52/200], Loss: 0.0476
Epoch [53/200], Loss: 0.0500
Epoch [54/200], Loss: 0.0476
Epoch [55/200], Loss: 0.0469
-- Evaluation after Epoch [55/200], Test Loss: 0.0843
Epoch [56/200], Loss: 0.0464
Epoch [57/200], Loss: 0.0475
Epoch [58/200], Loss: 0.0459
Epoch [59/200], Loss: 0.0466
Epoch [60/200], Loss: 0.0470
-- Evaluation after Epoch [60/200], Test Loss: 0.0955
Epoch [61/200], Loss: 0.0463
Epoch [62/200], Loss: 0.0478
Epoch [63/200], Loss: 0.0480
Epoch [64/200], Loss: 0.0462
Epoch [65/200], Loss: 0.0450
-- Evaluation after Epoch [65/200], Test Loss: 0.0766
New best test loss: 0.0766. Saving model.
Epoch [66/200], Loss: 0.0451
Epoch [67/200], Loss: 0.0444
Epoch [68/200], Loss: 0.0442
Epoch [69/200], Loss: 0.0447
Epoch [70/200], Loss: 0.0434
-- Evaluation after Epoch [70/200], Test Loss: 0.0868
Epoch [71/200], Loss: 0.0446
Epoch [72/200], Loss: 0.0443
Epoch [73/200], Loss: 0.0430
Epoch [74/200], Loss: 0.0427
Epoch [75/200], Loss: 0.0422
-- Evaluation after Epoch [75/200], Test Loss: 0.0835
Epoch [76/200], Loss: 0.0427
Epoch [77/200], Loss: 0.0423
Epoch [78/200], Loss: 0.0425
Epoch [79/200], Loss: 0.0424
Epoch [80/200], Loss: 0.0413
-- Evaluation after Epoch [80/200], Test Loss: 0.0774
Epoch [81/200], Loss: 0.0412
Epoch [82/200], Loss: 0.0416
Epoch [83/200], Loss: 0.0402
Epoch [84/200], Loss: 0.0412
Epoch [85/200], Loss: 0.0406
-- Evaluation after Epoch [85/200], Test Loss: 0.0815
Epoch [86/200], Loss: 0.0403
Epoch [87/200], Loss: 0.0415
Epoch [88/200], Loss: 0.0402
Epoch [89/200], Loss: 0.0386
Epoch [90/200], Loss: 0.0385
-- Evaluation after Epoch [90/200], Test Loss: 0.0778
Epoch [91/200], Loss: 0.0384
Epoch [92/200], Loss: 0.0388
Epoch [93/200], Loss: 0.0380
Epoch [94/200], Loss: 0.0377
Epoch [95/200], Loss: 0.0387
-- Evaluation after Epoch [95/200], Test Loss: 0.0714
New best test loss: 0.0714. Saving model.
Epoch [96/200], Loss: 0.0383
Epoch [97/200], Loss: 0.0378
Epoch [98/200], Loss: 0.0374
Epoch [99/200], Loss: 0.0365
Epoch [100/200], Loss: 0.0357
-- Evaluation after Epoch [100/200], Test Loss: 0.0746
Epoch [101/200], Loss: 0.0359
Epoch [102/200], Loss: 0.0366
Epoch [103/200], Loss: 0.0368
Epoch [104/200], Loss: 0.0353
Epoch [105/200], Loss: 0.0358
-- Evaluation after Epoch [105/200], Test Loss: 0.0700
New best test loss: 0.0700. Saving model.
Epoch [106/200], Loss: 0.0355
Epoch [107/200], Loss: 0.0346
Epoch [108/200], Loss: 0.0345
Epoch [109/200], Loss: 0.0344
Epoch [110/200], Loss: 0.0354
-- Evaluation after Epoch [110/200], Test Loss: 0.0737
Epoch [111/200], Loss: 0.0348
Epoch [112/200], Loss: 0.0340
Epoch [113/200], Loss: 0.0345
Epoch [114/200], Loss: 0.0338
Epoch [115/200], Loss: 0.0343
-- Evaluation after Epoch [115/200], Test Loss: 0.0677
New best test loss: 0.0677. Saving model.
Epoch [116/200], Loss: 0.0354
Epoch [117/200], Loss: 0.0343
Epoch [118/200], Loss: 0.0335
Epoch [119/200], Loss: 0.0330
Epoch [120/200], Loss: 0.0332
-- Evaluation after Epoch [120/200], Test Loss: 0.0675
New best test loss: 0.0675. Saving model.
Epoch [121/200], Loss: 0.0336
Epoch [122/200], Loss: 0.0332
Epoch [123/200], Loss: 0.0325
Epoch [124/200], Loss: 0.0329
Epoch [125/200], Loss: 0.0322
-- Evaluation after Epoch [125/200], Test Loss: 0.0652
New best test loss: 0.0652. Saving model.
Epoch [126/200], Loss: 0.0331
Epoch [127/200], Loss: 0.0335
Epoch [128/200], Loss: 0.0325
Epoch [129/200], Loss: 0.0355
Epoch [130/200], Loss: 0.0335
-- Evaluation after Epoch [130/200], Test Loss: 0.0656
Epoch [131/200], Loss: 0.0351
Epoch [132/200], Loss: 0.0345
Epoch [133/200], Loss: 0.0326
Epoch [134/200], Loss: 0.0325
Epoch [135/200], Loss: 0.0332
-- Evaluation after Epoch [135/200], Test Loss: 0.0655
Epoch [136/200], Loss: 0.0355
Epoch [137/200], Loss: 0.0370
Epoch [138/200], Loss: 0.0357
Epoch [139/200], Loss: 0.0352
Epoch [140/200], Loss: 0.0352
-- Evaluation after Epoch [140/200], Test Loss: 0.0683
Epoch [141/200], Loss: 0.0352
Epoch [142/200], Loss: 0.0353
Epoch [143/200], Loss: 0.0354
Epoch [144/200], Loss: 0.0348
Epoch [145/200], Loss: 0.0348
-- Evaluation after Epoch [145/200], Test Loss: 0.0717
Epoch [146/200], Loss: 0.0339
Epoch [147/200], Loss: 0.0338
Epoch [148/200], Loss: 0.0325
Epoch [149/200], Loss: 0.0312
Epoch [150/200], Loss: 0.0310
-- Evaluation after Epoch [150/200], Test Loss: 0.0688
Epoch [151/200], Loss: 0.0324
Epoch [152/200], Loss: 0.0307
Epoch [153/200], Loss: 0.0301
Epoch [154/200], Loss: 0.0307
Epoch [155/200], Loss: 0.0296
-- Evaluation after Epoch [155/200], Test Loss: 0.0741
Epoch [156/200], Loss: 0.0288
Epoch [157/200], Loss: 0.0312
Epoch [158/200], Loss: 0.0308
Epoch [159/200], Loss: 0.0299
Epoch [160/200], Loss: 0.0288
-- Evaluation after Epoch [160/200], Test Loss: 0.0762
Epoch [161/200], Loss: 0.0286
Epoch [162/200], Loss: 0.0288
Epoch [163/200], Loss: 0.0293
Epoch [164/200], Loss: 0.0314
Epoch [165/200], Loss: 0.0303
-- Evaluation after Epoch [165/200], Test Loss: 0.0828
Epoch [166/200], Loss: 0.0302
Epoch [167/200], Loss: 0.0319
Epoch [168/200], Loss: 0.0331
Epoch [169/200], Loss: 0.0311
Epoch [170/200], Loss: 0.0304
-- Evaluation after Epoch [170/200], Test Loss: 0.0673
Epoch [171/200], Loss: 0.0302
Epoch [172/200], Loss: 0.0306
Epoch [173/200], Loss: 0.0332
Epoch [174/200], Loss: 0.0333
Epoch [175/200], Loss: 0.0346
-- Evaluation after Epoch [175/200], Test Loss: 0.0773
Epoch [176/200], Loss: 0.0352
Epoch [177/200], Loss: 0.0322
Epoch [178/200], Loss: 0.0315
Epoch [179/200], Loss: 0.0302
Epoch [180/200], Loss: 0.0305
-- Evaluation after Epoch [180/200], Test Loss: 0.0808
Epoch [181/200], Loss: 0.0293
Epoch [182/200], Loss: 0.0303
Epoch [183/200], Loss: 0.0296
Epoch [184/200], Loss: 0.0304
Epoch [185/200], Loss: 0.0300
-- Evaluation after Epoch [185/200], Test Loss: 0.0805
Epoch [186/200], Loss: 0.0293
Epoch [187/200], Loss: 0.0293
Epoch [188/200], Loss: 0.0296
Epoch [189/200], Loss: 0.0314
Epoch [190/200], Loss: 0.0302
-- Evaluation after Epoch [190/200], Test Loss: 0.0677
Epoch [191/200], Loss: 0.0305
Epoch [192/200], Loss: 0.0311
Epoch [193/200], Loss: 0.0324
Epoch [194/200], Loss: 0.0334
Epoch [195/200], Loss: 0.0336
-- Evaluation after Epoch [195/200], Test Loss: 0.0596
New best test loss: 0.0596. Saving model.
Epoch [196/200], Loss: 0.0319
Epoch [197/200], Loss: 0.0301
Epoch [198/200], Loss: 0.0305
Epoch [199/200], Loss: 0.0306
Epoch [200/200], Loss: 0.0296
-- Evaluation after Epoch [200/200], Test Loss: 0.0647
Loading the best model from checkpoint with test loss: 0.0596
Validation Loss (RMSE): 0.0424
Validation results saved to: ./Results\LSTMStudy_20241218_125215\Val\validation_results.txt
Avg Test Loss before reverse scaling(RMSE): 0.0596
Avg Test Loss after reverse scaling (RMSE): 47.4740
Test results saved to: ./Results\LSTMStudy_20241218_125215\Test\test_results.txt
