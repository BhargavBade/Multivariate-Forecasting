Epoch [1/200], Loss: 0.1334
Epoch [2/200], Loss: 0.0921
Epoch [3/200], Loss: 0.0889
Epoch [4/200], Loss: 0.0880
Epoch [5/200], Loss: 0.0877
-- Evaluation after Epoch [5/200], Test Loss: 0.0770
Epoch [6/200], Loss: 0.0877
Epoch [7/200], Loss: 0.0876
Epoch [8/200], Loss: 0.0876
Epoch [9/200], Loss: 0.0876
Epoch [10/200], Loss: 0.0876
-- Evaluation after Epoch [10/200], Test Loss: 0.0772
Epoch [11/200], Loss: 0.0876
Epoch [12/200], Loss: 0.0876
Epoch [13/200], Loss: 0.0876
Epoch [14/200], Loss: 0.0877
Epoch [15/200], Loss: 0.0876
-- Evaluation after Epoch [15/200], Test Loss: 0.0771
Epoch [16/200], Loss: 0.0875
Epoch [17/200], Loss: 0.0865
Epoch [18/200], Loss: 0.0857
Epoch [19/200], Loss: 0.0850
Epoch [20/200], Loss: 0.0840
-- Evaluation after Epoch [20/200], Test Loss: 0.0712
New best test loss: 0.0712. Saving model.
Epoch [21/200], Loss: 0.0836
Epoch [22/200], Loss: 0.0831
Epoch [23/200], Loss: 0.0831
Epoch [24/200], Loss: 0.0825
Epoch [25/200], Loss: 0.0819
-- Evaluation after Epoch [25/200], Test Loss: 0.0695
New best test loss: 0.0695. Saving model.
Epoch [26/200], Loss: 0.0824
Epoch [27/200], Loss: 0.0820
Epoch [28/200], Loss: 0.0819
Epoch [29/200], Loss: 0.0811
Epoch [30/200], Loss: 0.0816
-- Evaluation after Epoch [30/200], Test Loss: 0.0687
New best test loss: 0.0687. Saving model.
Epoch [31/200], Loss: 0.0801
Epoch [32/200], Loss: 0.0807
Epoch [33/200], Loss: 0.0800
Epoch [34/200], Loss: 0.0793
Epoch [35/200], Loss: 0.0792
-- Evaluation after Epoch [35/200], Test Loss: 0.0678
New best test loss: 0.0678. Saving model.
Epoch [36/200], Loss: 0.0794
Epoch [37/200], Loss: 0.0788
Epoch [38/200], Loss: 0.0784
Epoch [39/200], Loss: 0.0785
Epoch [40/200], Loss: 0.0786
-- Evaluation after Epoch [40/200], Test Loss: 0.0677
New best test loss: 0.0677. Saving model.
Epoch [41/200], Loss: 0.0778
Epoch [42/200], Loss: 0.0774
Epoch [43/200], Loss: 0.0777
Epoch [44/200], Loss: 0.0780
Epoch [45/200], Loss: 0.0770
-- Evaluation after Epoch [45/200], Test Loss: 0.0666
New best test loss: 0.0666. Saving model.
Epoch [46/200], Loss: 0.0767
Epoch [47/200], Loss: 0.0773
Epoch [48/200], Loss: 0.0762
Epoch [49/200], Loss: 0.0754
Epoch [50/200], Loss: 0.0759
-- Evaluation after Epoch [50/200], Test Loss: 0.0658
New best test loss: 0.0658. Saving model.
Epoch [51/200], Loss: 0.0756
Epoch [52/200], Loss: 0.0764
Epoch [53/200], Loss: 0.0756
Epoch [54/200], Loss: 0.0749
Epoch [55/200], Loss: 0.0746
-- Evaluation after Epoch [55/200], Test Loss: 0.0659
Epoch [56/200], Loss: 0.0747
Epoch [57/200], Loss: 0.0745
Epoch [58/200], Loss: 0.0743
Epoch [59/200], Loss: 0.0753
Epoch [60/200], Loss: 0.0745
-- Evaluation after Epoch [60/200], Test Loss: 0.0661
Epoch [61/200], Loss: 0.0740
Epoch [62/200], Loss: 0.0742
Epoch [63/200], Loss: 0.0739
Epoch [64/200], Loss: 0.0743
Epoch [65/200], Loss: 0.0736
-- Evaluation after Epoch [65/200], Test Loss: 0.0676
Epoch [66/200], Loss: 0.0722
Epoch [67/200], Loss: 0.0719
Epoch [68/200], Loss: 0.0722
Epoch [69/200], Loss: 0.0718
Epoch [70/200], Loss: 0.0721
-- Evaluation after Epoch [70/200], Test Loss: 0.0671
Epoch [71/200], Loss: 0.0718
Epoch [72/200], Loss: 0.0716
Epoch [73/200], Loss: 0.0702
Epoch [74/200], Loss: 0.0704
Epoch [75/200], Loss: 0.0697
-- Evaluation after Epoch [75/200], Test Loss: 0.0688
Epoch [76/200], Loss: 0.0704
Epoch [77/200], Loss: 0.0698
Epoch [78/200], Loss: 0.0706
Epoch [79/200], Loss: 0.0708
Epoch [80/200], Loss: 0.0717
-- Evaluation after Epoch [80/200], Test Loss: 0.0688
Epoch [81/200], Loss: 0.0703
Epoch [82/200], Loss: 0.0704
Epoch [83/200], Loss: 0.0689
Epoch [84/200], Loss: 0.0682
Epoch [85/200], Loss: 0.0686
-- Evaluation after Epoch [85/200], Test Loss: 0.0709
Epoch [86/200], Loss: 0.0710
Epoch [87/200], Loss: 0.0691
Epoch [88/200], Loss: 0.0680
Epoch [89/200], Loss: 0.0683
Epoch [90/200], Loss: 0.0688
-- Evaluation after Epoch [90/200], Test Loss: 0.0689
Epoch [91/200], Loss: 0.0680
Epoch [92/200], Loss: 0.0680
Epoch [93/200], Loss: 0.0681
Epoch [94/200], Loss: 0.0665
Epoch [95/200], Loss: 0.0663
-- Evaluation after Epoch [95/200], Test Loss: 0.0705
Epoch [96/200], Loss: 0.0666
Epoch [97/200], Loss: 0.0673
Epoch [98/200], Loss: 0.0667
Epoch [99/200], Loss: 0.0664
Epoch [100/200], Loss: 0.0654
-- Evaluation after Epoch [100/200], Test Loss: 0.0749
Epoch [101/200], Loss: 0.0672
Epoch [102/200], Loss: 0.0678
Epoch [103/200], Loss: 0.0648
Epoch [104/200], Loss: 0.0643
Epoch [105/200], Loss: 0.0640
-- Evaluation after Epoch [105/200], Test Loss: 0.0772
Epoch [106/200], Loss: 0.0645
Epoch [107/200], Loss: 0.0649
Epoch [108/200], Loss: 0.0642
Epoch [109/200], Loss: 0.0639
Epoch [110/200], Loss: 0.0645
-- Evaluation after Epoch [110/200], Test Loss: 0.0766
Epoch [111/200], Loss: 0.0629
Epoch [112/200], Loss: 0.0634
Epoch [113/200], Loss: 0.0616
Epoch [114/200], Loss: 0.0626
Epoch [115/200], Loss: 0.0624
-- Evaluation after Epoch [115/200], Test Loss: 0.0805
Epoch [116/200], Loss: 0.0625
Epoch [117/200], Loss: 0.0638
Epoch [118/200], Loss: 0.0643
Epoch [119/200], Loss: 0.0624
Epoch [120/200], Loss: 0.0616
-- Evaluation after Epoch [120/200], Test Loss: 0.0798
Epoch [121/200], Loss: 0.0609
Epoch [122/200], Loss: 0.0644
Epoch [123/200], Loss: 0.0624
Epoch [124/200], Loss: 0.0604
Epoch [125/200], Loss: 0.0596
-- Evaluation after Epoch [125/200], Test Loss: 0.0793
Epoch [126/200], Loss: 0.0612
Epoch [127/200], Loss: 0.0602
Epoch [128/200], Loss: 0.0597
Epoch [129/200], Loss: 0.0586
Epoch [130/200], Loss: 0.0583
-- Evaluation after Epoch [130/200], Test Loss: 0.0780
Epoch [131/200], Loss: 0.0586
Epoch [132/200], Loss: 0.0595
Epoch [133/200], Loss: 0.0583
Epoch [134/200], Loss: 0.0580
Epoch [135/200], Loss: 0.0606
-- Evaluation after Epoch [135/200], Test Loss: 0.0823
Epoch [136/200], Loss: 0.0586
Epoch [137/200], Loss: 0.0589
Epoch [138/200], Loss: 0.0601
Epoch [139/200], Loss: 0.0610
Epoch [140/200], Loss: 0.0597
-- Evaluation after Epoch [140/200], Test Loss: 0.0782
Epoch [141/200], Loss: 0.0582
Epoch [142/200], Loss: 0.0581
Epoch [143/200], Loss: 0.0581
Epoch [144/200], Loss: 0.0574
Epoch [145/200], Loss: 0.0565
-- Evaluation after Epoch [145/200], Test Loss: 0.0811
Epoch [146/200], Loss: 0.0568
Epoch [147/200], Loss: 0.0566
Epoch [148/200], Loss: 0.0567
Epoch [149/200], Loss: 0.0564
Epoch [150/200], Loss: 0.0554
-- Evaluation after Epoch [150/200], Test Loss: 0.0806
Epoch [151/200], Loss: 0.0550
Epoch [152/200], Loss: 0.0556
Epoch [153/200], Loss: 0.0556
Epoch [154/200], Loss: 0.0561
Epoch [155/200], Loss: 0.0537
-- Evaluation after Epoch [155/200], Test Loss: 0.0804
Epoch [156/200], Loss: 0.0545
Epoch [157/200], Loss: 0.0549
Epoch [158/200], Loss: 0.0543
Epoch [159/200], Loss: 0.0540
Epoch [160/200], Loss: 0.0547
-- Evaluation after Epoch [160/200], Test Loss: 0.0836
Epoch [161/200], Loss: 0.0552
Epoch [162/200], Loss: 0.0567
Epoch [163/200], Loss: 0.0540
Epoch [164/200], Loss: 0.0541
Epoch [165/200], Loss: 0.0533
-- Evaluation after Epoch [165/200], Test Loss: 0.0807
Epoch [166/200], Loss: 0.0545
Epoch [167/200], Loss: 0.0532
Epoch [168/200], Loss: 0.0535
Epoch [169/200], Loss: 0.0523
Epoch [170/200], Loss: 0.0532
-- Evaluation after Epoch [170/200], Test Loss: 0.0796
Epoch [171/200], Loss: 0.0539
Epoch [172/200], Loss: 0.0534
Epoch [173/200], Loss: 0.0519
Epoch [174/200], Loss: 0.0531
Epoch [175/200], Loss: 0.0518
-- Evaluation after Epoch [175/200], Test Loss: 0.0795
Epoch [176/200], Loss: 0.0514
Epoch [177/200], Loss: 0.0546
Epoch [178/200], Loss: 0.0545
Epoch [179/200], Loss: 0.0523
Epoch [180/200], Loss: 0.0513
-- Evaluation after Epoch [180/200], Test Loss: 0.0772
Epoch [181/200], Loss: 0.0528
Epoch [182/200], Loss: 0.0510
Epoch [183/200], Loss: 0.0507
Epoch [184/200], Loss: 0.0511
Epoch [185/200], Loss: 0.0499
-- Evaluation after Epoch [185/200], Test Loss: 0.0777
Epoch [186/200], Loss: 0.0503
Epoch [187/200], Loss: 0.0494
Epoch [188/200], Loss: 0.0510
Epoch [189/200], Loss: 0.0505
Epoch [190/200], Loss: 0.0499
-- Evaluation after Epoch [190/200], Test Loss: 0.0797
Epoch [191/200], Loss: 0.0492
Epoch [192/200], Loss: 0.0499
Epoch [193/200], Loss: 0.0488
Epoch [194/200], Loss: 0.0493
Epoch [195/200], Loss: 0.0501
-- Evaluation after Epoch [195/200], Test Loss: 0.0774
Epoch [196/200], Loss: 0.0495
Epoch [197/200], Loss: 0.0501
Epoch [198/200], Loss: 0.0491
Epoch [199/200], Loss: 0.0479
Epoch [200/200], Loss: 0.0475
-- Evaluation after Epoch [200/200], Test Loss: 0.0770
Loading the best model from checkpoint with test loss: 0.0658
Validation Loss (RMSE): 0.0658
Validation results saved to: ./Results\LSTM_Study_20250131_121534\Val\validation_results.txt
Avg Test Loss before reverse scaling(RMSE): 0.0658
Avg Test Loss after reverse scaling (RMSE): 48.5944
Test results saved to: ./Results\LSTM_Study_20250131_121534\Test\test_results.txt
