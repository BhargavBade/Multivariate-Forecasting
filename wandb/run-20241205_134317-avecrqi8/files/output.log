Epoch [1/200], Loss: 0.0878
Epoch [2/200], Loss: 0.0844
Epoch [3/200], Loss: 0.0837
Epoch [4/200], Loss: 0.0834
Epoch [5/200], Loss: 0.0830
-- Evaluation after Epoch [5/200], Test Loss: 0.0791
New best test loss: 0.0791. Saving model.
Epoch [6/200], Loss: 0.0827
Epoch [7/200], Loss: 0.0826
Epoch [8/200], Loss: 0.0824
Epoch [9/200], Loss: 0.0822
Epoch [10/200], Loss: 0.0821
-- Evaluation after Epoch [10/200], Test Loss: 0.0814
Epoch [11/200], Loss: 0.0820
Epoch [12/200], Loss: 0.0819
Epoch [13/200], Loss: 0.0819
Epoch [14/200], Loss: 0.0819
Epoch [15/200], Loss: 0.0818
-- Evaluation after Epoch [15/200], Test Loss: 0.0844
Epoch [16/200], Loss: 0.0818
Epoch [17/200], Loss: 0.0817
Epoch [18/200], Loss: 0.0817
Epoch [19/200], Loss: 0.0817
Epoch [20/200], Loss: 0.0816
-- Evaluation after Epoch [20/200], Test Loss: 0.0868
Epoch [21/200], Loss: 0.0816
Epoch [22/200], Loss: 0.0814
Epoch [23/200], Loss: 0.0816
Epoch [24/200], Loss: 0.0815
Epoch [25/200], Loss: 0.0773
-- Evaluation after Epoch [25/200], Test Loss: 0.0893
Epoch [26/200], Loss: 0.0694
Epoch [27/200], Loss: 0.0681
Epoch [28/200], Loss: 0.0672
Epoch [29/200], Loss: 0.0668
Epoch [30/200], Loss: 0.0660
-- Evaluation after Epoch [30/200], Test Loss: 0.0955
Epoch [31/200], Loss: 0.0656
Epoch [32/200], Loss: 0.0649
Epoch [33/200], Loss: 0.0645
Epoch [34/200], Loss: 0.0646
Epoch [35/200], Loss: 0.0640
-- Evaluation after Epoch [35/200], Test Loss: 0.0966
Epoch [36/200], Loss: 0.0638
Epoch [37/200], Loss: 0.0633
Epoch [38/200], Loss: 0.0631
Epoch [39/200], Loss: 0.0628
Epoch [40/200], Loss: 0.0626
-- Evaluation after Epoch [40/200], Test Loss: 0.0960
Epoch [41/200], Loss: 0.0622
Epoch [42/200], Loss: 0.0621
Epoch [43/200], Loss: 0.0616
Epoch [44/200], Loss: 0.0613
Epoch [45/200], Loss: 0.0615
-- Evaluation after Epoch [45/200], Test Loss: 0.0974
Epoch [46/200], Loss: 0.0614
Epoch [47/200], Loss: 0.0606
Epoch [48/200], Loss: 0.0608
Epoch [49/200], Loss: 0.0622
Epoch [50/200], Loss: 0.0607
-- Evaluation after Epoch [50/200], Test Loss: 0.0908
Epoch [51/200], Loss: 0.0600
Epoch [52/200], Loss: 0.0599
Epoch [53/200], Loss: 0.0588
Epoch [54/200], Loss: 0.0588
Epoch [55/200], Loss: 0.0583
-- Evaluation after Epoch [55/200], Test Loss: 0.0920
Epoch [56/200], Loss: 0.0577
Epoch [57/200], Loss: 0.0578
Epoch [58/200], Loss: 0.0578
Epoch [59/200], Loss: 0.0568
Epoch [60/200], Loss: 0.0570
-- Evaluation after Epoch [60/200], Test Loss: 0.0845
Epoch [61/200], Loss: 0.0572
Epoch [62/200], Loss: 0.0558
Epoch [63/200], Loss: 0.0556
Epoch [64/200], Loss: 0.0569
Epoch [65/200], Loss: 0.0562
-- Evaluation after Epoch [65/200], Test Loss: 0.0819
Epoch [66/200], Loss: 0.0552
Epoch [67/200], Loss: 0.0549
Epoch [68/200], Loss: 0.0543
Epoch [69/200], Loss: 0.0547
Epoch [70/200], Loss: 0.0529
-- Evaluation after Epoch [70/200], Test Loss: 0.0781
New best test loss: 0.0781. Saving model.
Epoch [71/200], Loss: 0.0532
Epoch [72/200], Loss: 0.0535
Epoch [73/200], Loss: 0.0524
Epoch [74/200], Loss: 0.0529
Epoch [75/200], Loss: 0.0522
-- Evaluation after Epoch [75/200], Test Loss: 0.0770
New best test loss: 0.0770. Saving model.
Epoch [76/200], Loss: 0.0521
Epoch [77/200], Loss: 0.0531
Epoch [78/200], Loss: 0.0514
Epoch [79/200], Loss: 0.0508
Epoch [80/200], Loss: 0.0513
-- Evaluation after Epoch [80/200], Test Loss: 0.0758
New best test loss: 0.0758. Saving model.
Epoch [81/200], Loss: 0.0509
Epoch [82/200], Loss: 0.0505
Epoch [83/200], Loss: 0.0499
Epoch [84/200], Loss: 0.0503
Epoch [85/200], Loss: 0.0497
-- Evaluation after Epoch [85/200], Test Loss: 0.0680
New best test loss: 0.0680. Saving model.
Epoch [86/200], Loss: 0.0496
Epoch [87/200], Loss: 0.0495
Epoch [88/200], Loss: 0.0498
Epoch [89/200], Loss: 0.0483
Epoch [90/200], Loss: 0.0484
-- Evaluation after Epoch [90/200], Test Loss: 0.0685
Epoch [91/200], Loss: 0.0479
Epoch [92/200], Loss: 0.0472
Epoch [93/200], Loss: 0.0473
Epoch [94/200], Loss: 0.0471
Epoch [95/200], Loss: 0.0473
-- Evaluation after Epoch [95/200], Test Loss: 0.0727
Epoch [96/200], Loss: 0.0474
Epoch [97/200], Loss: 0.0471
Epoch [98/200], Loss: 0.0469
Epoch [99/200], Loss: 0.0464
Epoch [100/200], Loss: 0.0453
-- Evaluation after Epoch [100/200], Test Loss: 0.0798
Epoch [101/200], Loss: 0.0467
Epoch [102/200], Loss: 0.0458
Epoch [103/200], Loss: 0.0449
Epoch [104/200], Loss: 0.0454
Epoch [105/200], Loss: 0.0438
-- Evaluation after Epoch [105/200], Test Loss: 0.0755
Epoch [106/200], Loss: 0.0443
Epoch [107/200], Loss: 0.0434
Epoch [108/200], Loss: 0.0461
Epoch [109/200], Loss: 0.0433
Epoch [110/200], Loss: 0.0433
-- Evaluation after Epoch [110/200], Test Loss: 0.0718
Epoch [111/200], Loss: 0.0433
Epoch [112/200], Loss: 0.0419
Epoch [113/200], Loss: 0.0417
Epoch [114/200], Loss: 0.0446
Epoch [115/200], Loss: 0.0423
-- Evaluation after Epoch [115/200], Test Loss: 0.0666
New best test loss: 0.0666. Saving model.
Epoch [116/200], Loss: 0.0411
Epoch [117/200], Loss: 0.0405
Epoch [118/200], Loss: 0.0400
Epoch [119/200], Loss: 0.0402
Epoch [120/200], Loss: 0.0407
-- Evaluation after Epoch [120/200], Test Loss: 0.0713
Epoch [121/200], Loss: 0.0399
Epoch [122/200], Loss: 0.0396
Epoch [123/200], Loss: 0.0407
Epoch [124/200], Loss: 0.0394
Epoch [125/200], Loss: 0.0396
-- Evaluation after Epoch [125/200], Test Loss: 0.0642
New best test loss: 0.0642. Saving model.
Epoch [126/200], Loss: 0.0393
Epoch [127/200], Loss: 0.0384
Epoch [128/200], Loss: 0.0384
Epoch [129/200], Loss: 0.0394
Epoch [130/200], Loss: 0.0379
-- Evaluation after Epoch [130/200], Test Loss: 0.0664
Epoch [131/200], Loss: 0.0382
Epoch [132/200], Loss: 0.0371
Epoch [133/200], Loss: 0.0391
Epoch [134/200], Loss: 0.0372
Epoch [135/200], Loss: 0.0360
-- Evaluation after Epoch [135/200], Test Loss: 0.0663
Epoch [136/200], Loss: 0.0365
Epoch [137/200], Loss: 0.0360
Epoch [138/200], Loss: 0.0363
Epoch [139/200], Loss: 0.0371
Epoch [140/200], Loss: 0.0356
-- Evaluation after Epoch [140/200], Test Loss: 0.0670
Epoch [141/200], Loss: 0.0357
Epoch [142/200], Loss: 0.0370
Epoch [143/200], Loss: 0.0355
Epoch [144/200], Loss: 0.0350
Epoch [145/200], Loss: 0.0355
-- Evaluation after Epoch [145/200], Test Loss: 0.0635
New best test loss: 0.0635. Saving model.
Epoch [146/200], Loss: 0.0349
Epoch [147/200], Loss: 0.0348
Epoch [148/200], Loss: 0.0346
Epoch [149/200], Loss: 0.0351
Epoch [150/200], Loss: 0.0363
-- Evaluation after Epoch [150/200], Test Loss: 0.0676
Epoch [151/200], Loss: 0.0354
Epoch [152/200], Loss: 0.0334
Epoch [153/200], Loss: 0.0329
Epoch [154/200], Loss: 0.0328
Epoch [155/200], Loss: 0.0337
-- Evaluation after Epoch [155/200], Test Loss: 0.0653
Epoch [156/200], Loss: 0.0339
Epoch [157/200], Loss: 0.0333
Epoch [158/200], Loss: 0.0335
Epoch [159/200], Loss: 0.0329
Epoch [160/200], Loss: 0.0322
-- Evaluation after Epoch [160/200], Test Loss: 0.0712
Epoch [161/200], Loss: 0.0326
Epoch [162/200], Loss: 0.0350
Epoch [163/200], Loss: 0.0329
Epoch [164/200], Loss: 0.0322
Epoch [165/200], Loss: 0.0332
-- Evaluation after Epoch [165/200], Test Loss: 0.0660
Epoch [166/200], Loss: 0.0324
Epoch [167/200], Loss: 0.0319
Epoch [168/200], Loss: 0.0316
Epoch [169/200], Loss: 0.0322
Epoch [170/200], Loss: 0.0325
-- Evaluation after Epoch [170/200], Test Loss: 0.0648
Epoch [171/200], Loss: 0.0326
Epoch [172/200], Loss: 0.0318
Epoch [173/200], Loss: 0.0323
Epoch [174/200], Loss: 0.0318
Epoch [175/200], Loss: 0.0311
-- Evaluation after Epoch [175/200], Test Loss: 0.0660
Epoch [176/200], Loss: 0.0305
Epoch [177/200], Loss: 0.0312
Epoch [178/200], Loss: 0.0309
Epoch [179/200], Loss: 0.0309
Epoch [180/200], Loss: 0.0310
-- Evaluation after Epoch [180/200], Test Loss: 0.0648
Epoch [181/200], Loss: 0.0309
Epoch [182/200], Loss: 0.0310
Epoch [183/200], Loss: 0.0307
Epoch [184/200], Loss: 0.0306
Epoch [185/200], Loss: 0.0297
-- Evaluation after Epoch [185/200], Test Loss: 0.0655
Epoch [186/200], Loss: 0.0306
Epoch [187/200], Loss: 0.0321
Epoch [188/200], Loss: 0.0319
Epoch [189/200], Loss: 0.0331
Epoch [190/200], Loss: 0.0318
-- Evaluation after Epoch [190/200], Test Loss: 0.0646
Epoch [191/200], Loss: 0.0303
Epoch [192/200], Loss: 0.0305
Epoch [193/200], Loss: 0.0300
Epoch [194/200], Loss: 0.0303
Epoch [195/200], Loss: 0.0305
-- Evaluation after Epoch [195/200], Test Loss: 0.0616
New best test loss: 0.0616. Saving model.
Epoch [196/200], Loss: 0.0314
Epoch [197/200], Loss: 0.0309
Epoch [198/200], Loss: 0.0309
Epoch [199/200], Loss: 0.0295
Epoch [200/200], Loss: 0.0290
-- Evaluation after Epoch [200/200], Test Loss: 0.0662
Loading the best model from checkpoint with test loss: 0.0616
Validation Loss (RMSE): 0.0515
Validation results saved to: ./Results\LSTMStudy_20241205_134222\Val\validation_results.txt
Avg Test Loss before reverse scaling(RMSE): 0.0616
Avg Test Loss after reverse scaling (RMSE): 48.4960
Test results saved to: ./Results\LSTMStudy_20241205_134222\Test\test_results.txt
